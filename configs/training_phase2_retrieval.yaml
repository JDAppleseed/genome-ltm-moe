schema_version: 1
model:
  type: "moe_mlm"
  d_model: 512
  n_layers: 4
  n_experts: 4
  d_ff: 1024
training:
  steps: 500
  micro_batch_size: 2
  train_batch_size: 32
data:
  synthetic: true
  seq_len: 1024
